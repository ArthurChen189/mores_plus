{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as jnp\n",
    "import jax\n",
    "import transformers\n",
    "import optax\n",
    "from flax.training import train_state\n",
    "import flax.linen as nn\n",
    "\n",
    "import data\n",
    "import modeling_bart\n",
    "import arguments\n",
    "import datasets\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './training'\n",
    "TRAIN_DATA = './training/train_dataset'\n",
    "DEV_DATA = './training/dev_dataset'\n",
    "RANK_SCORE_PATH = './training'\n",
    "\n",
    "PATH_TO_TSV = './training/json_files/sample_train.json'\n",
    "\n",
    "data_args = arguments.DataArguments(train_dir=TRAIN_DIR,train_path=TRAIN_DATA,dev_path=DEV_DATA,rank_score_path=RANK_SCORE_PATH,max_len=512)\n",
    "reranker_args = arguments.RerankerTrainingArguments(output_dir=os.path.join(TRAIN_DIR,'output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = transformers.BartConfig()\n",
    "tokenizer = transformers.BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
    "# model = modeling_bart.FlaxBartMoresRanker(config=config)\n",
    "query_model = modeling_bart.FlaxBartMoresRanker.from_pretrained('facebook/bart-base')\n",
    "document_model = modeling_bart.FlaxBartMoresRanker.from_pretrained('facebook/bart-base')\n",
    "# model = modeling_bart.FlaxBartMoresRanker.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.GroupedTrainDataset(args=data_args,path_to_tsv=PATH_TO_TSV,tokenizer=tokenizer,train_args=reranker_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "def compute_lce(params, input_ids, pos):\n",
    "    logits = IB.apply({'params':params},input_ids)\n",
    "    if pos:\n",
    "        loss = optax.softmax_cross_entropy(logits=logits,labels=jnp.array([1,0],dtype=jnp.float32)).mean()\n",
    "    else:\n",
    "        loss = optax.softmax_cross_entropy(logits=logits,labels=jnp.array([0,1],dtype=jnp.float32)).mean()\n",
    "    return loss\n",
    "\n",
    "def compute_lce_2(logits, pos):\n",
    "    if pos:\n",
    "        loss = optax.softmax_cross_entropy(logits=logits,labels=jnp.array([1,0],dtype=jnp.float32)).mean()\n",
    "    else:\n",
    "        loss = optax.softmax_cross_entropy(logits=logits,labels=jnp.array([0,1],dtype=jnp.float32)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionBlock(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self,x):\n",
    "        # print(x.shape)\n",
    "        # Q,D = x\n",
    "        Q = x[:,0]\n",
    "        D = x[:,1:].reshape(1,3*512,768)\n",
    "        # print(Q.shape)\n",
    "        # print(D.shape)\n",
    "        x = nn.MultiHeadDotProductAttention(num_heads=6)(inputs_q=Q,inputs_kv=D)\n",
    "        x = nn.LayerNorm()(x+Q)\n",
    "        x = nn.LayerNorm()(nn.SelfAttention(num_heads=6)(x)) + x\n",
    "        x = nn.LayerNorm()(nn.Dense(features=Q.shape[-1])(x) + x)\n",
    "        return x\n",
    "\n",
    "class IB2(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self,x):\n",
    "        # _, D = x\n",
    "        D = x[:,1:]\n",
    "        x = InteractionBlock()(x)\n",
    "        x = InteractionBlock()(jnp.concatenate((jnp.expand_dims(x,axis=0),D),axis=1).reshape(1,4,512,768))\n",
    "        cls_tok = x[:,0]\n",
    "        x = nn.Dense(features=2)(cls_tok)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "IB = IB2()\n",
    "params = IB.init(key, jnp.ones([1, 4, 512, 768]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits):\n",
    "  pos, neg = logits\n",
    "  loss = compute_lce_2(logits=pos, pos=1)\n",
    "  loss += compute_lce_2(logits=neg, pos=0)\n",
    "  pred = jnp.array([jnp.argmax(pos,-1), jnp.argmax(neg,-1)])\n",
    "  accuracy = jnp.mean(pred.flatten() == jnp.array([1,0]))\n",
    "  # print(f\"accuracy is {accuracy}\\tloss is {loss}\")\n",
    "  metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "  }\n",
    "\n",
    "  return metrics\n",
    "\n",
    "# @jax.jit\n",
    "def eval_step(params, batch):\n",
    "  pos, neg = batch\n",
    "  pos_logits = IB2().apply({'params': params}, pos)\n",
    "  neg_logits = IB2().apply({'params': params}, neg)\n",
    "\n",
    "  return compute_metrics(logits=(pos_logits,neg_logits))\n",
    "  \n",
    "def eval_model(params, batch):\n",
    "  metrics = eval_step(params, batch)\n",
    "  # metrics = jax.device_get(metrics)\n",
    "  # summary = jax.tree_util.tree_map(lambda x: x.item(), metrics)\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate, momentum):\n",
    "  \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "  # query_enc = modeling_bart.FlaxBartMoresRanker.from_pretrained('facebook/bart-base')\n",
    "  # document_enc = modeling_bart.FlaxBartMoresRanker.from_pretrained('facebook/bart-base')\n",
    "  IB = IB2()\n",
    "  params = IB.init(rng, jnp.ones([1, 4, 512, 768]))['params']\n",
    "  tx = optax.sgd(learning_rate, momentum)\n",
    "  return train_state.TrainState.create(\n",
    "      apply_fn=IB.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "state = create_train_state(key, 2e-4, 0.9)\n",
    "del key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jax.jit\n",
    "def train_step(state, batch, label):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  grad_fn = jax.grad(compute_lce, has_aux=False)\n",
    "  grads = grad_fn(state.params, batch, label)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  return state\n",
    "\n",
    "def train_epoch(state, batch):\n",
    "  \"\"\"Train for a single epoch.\"\"\"\n",
    "  # compute mean of metrics across each batch in epoch.\n",
    "  pos,neg = batch\n",
    "  # pos train\n",
    "  state = train_step(state, pos, label=1)\n",
    "  state = train_step(state, neg ,label=0)\n",
    "   \n",
    "  return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 10\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    accuracy = []\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "    for pos,neg in train_dataset:\n",
    "        query = query_model(jnp.expand_dims(pos[0],axis=0))[1]\n",
    "        pos_emb = document_model(pos[1])[1]\n",
    "        neg_emb = document_model(neg[1])[1]\n",
    "        pos_emb = jnp.expand_dims(jnp.concatenate((query, pos_emb),axis=0),axis=0)\n",
    "        neg_emb = jnp.expand_dims(jnp.concatenate((query, neg_emb),axis=0),axis=0)\n",
    "\n",
    "        state = train_epoch(state, (pos_emb,neg_emb))\n",
    "        metrics = eval_model(state.params, (pos_emb,neg_emb))\n",
    "        acc += metrics['accuracy'].item()\n",
    "        loss += metrics['loss'].item()\n",
    "\n",
    "    print(f' test epoch: {epoch}, loss: {loss/len(train_dataset)}, accuracy: {acc/len(train_dataset) * 100}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce192cc7f25a26e7f74bc48c6e381b56c5d8d841b5bd0d44111db8eabaee7fe6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('flax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
